{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 1\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the Housing Price Prediction Dataset**\n",
    "\n",
    "* Using housing price prediction dataset, we will be training the multivairate linear regression model to predict the price of house based on house features like area, number of bedrooms, number of stories etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the dataset using pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 2\n",
    "df = pd.read_csv(\"../data/housing_price_prediction.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we could see the dataset consists both numeric and categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study the data statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.450000e+02</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.766729e+06</td>\n",
       "      <td>5150.541284</td>\n",
       "      <td>2.965138</td>\n",
       "      <td>1.286239</td>\n",
       "      <td>1.805505</td>\n",
       "      <td>0.693578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.870440e+06</td>\n",
       "      <td>2170.141023</td>\n",
       "      <td>0.738064</td>\n",
       "      <td>0.502470</td>\n",
       "      <td>0.867492</td>\n",
       "      <td>0.861586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.750000e+06</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.430000e+06</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.340000e+06</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.740000e+06</td>\n",
       "      <td>6360.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.330000e+07</td>\n",
       "      <td>16200.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price          area    bedrooms   bathrooms     stories  \\\n",
       "count  5.450000e+02    545.000000  545.000000  545.000000  545.000000   \n",
       "mean   4.766729e+06   5150.541284    2.965138    1.286239    1.805505   \n",
       "std    1.870440e+06   2170.141023    0.738064    0.502470    0.867492   \n",
       "min    1.750000e+06   1650.000000    1.000000    1.000000    1.000000   \n",
       "25%    3.430000e+06   3600.000000    2.000000    1.000000    1.000000   \n",
       "50%    4.340000e+06   4600.000000    3.000000    1.000000    2.000000   \n",
       "75%    5.740000e+06   6360.000000    3.000000    2.000000    2.000000   \n",
       "max    1.330000e+07  16200.000000    6.000000    4.000000    4.000000   \n",
       "\n",
       "          parking  \n",
       "count  545.000000  \n",
       "mean     0.693578  \n",
       "std      0.861586  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      3.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 3\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we could see the maximum and minimum value of different features are of different range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# cell 4\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we could see there are no missing values in all feature columns as 545 out of 545 are non-null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting the categorical features into numeric features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "      <th>mainroad_yes</th>\n",
       "      <th>guestroom_yes</th>\n",
       "      <th>basement_yes</th>\n",
       "      <th>hotwaterheating_yes</th>\n",
       "      <th>airconditioning_yes</th>\n",
       "      <th>prefarea_yes</th>\n",
       "      <th>furnishingstatus_semi-furnished</th>\n",
       "      <th>furnishingstatus_unfurnished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories  parking  mainroad_yes  \\\n",
       "0  13300000  7420         4          2        3        2          True   \n",
       "1  12250000  8960         4          4        4        3          True   \n",
       "2  12250000  9960         3          2        2        2          True   \n",
       "3  12215000  7500         4          2        2        3          True   \n",
       "4  11410000  7420         4          1        2        2          True   \n",
       "\n",
       "   guestroom_yes  basement_yes  hotwaterheating_yes  airconditioning_yes  \\\n",
       "0          False         False                False                 True   \n",
       "1          False         False                False                 True   \n",
       "2          False          True                False                False   \n",
       "3          False          True                False                 True   \n",
       "4           True          True                False                 True   \n",
       "\n",
       "   prefarea_yes  furnishingstatus_semi-furnished  furnishingstatus_unfurnished  \n",
       "0          True                            False                         False  \n",
       "1         False                            False                         False  \n",
       "2          True                             True                         False  \n",
       "3          True                            False                         False  \n",
       "4         False                            False                         False  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 5\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separating the Input features and output target variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6\n",
    "# All the columns except 'price' are our input features\n",
    "X = df.drop('price', axis=1).values  # X is our feature matrix and axis=1 means columns\n",
    "\n",
    "# 'price' is our target variable\n",
    "y = df['price'].values  # y is our label/target/ground_truth vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of feature matrix: (545, 13)\n",
      "Dimension of label vector: (545,)\n"
     ]
    }
   ],
   "source": [
    "# cell 7\n",
    "print(f\"Dimension of feature matrix: {X.shape}\")\n",
    "print(f\"Dimension of label vector: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we could see there are 545 total examples in dataset and we will be using 13 different features.We should reshape the label vector to pervent matrix dimensional confict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reshaping the label vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of label vector: (545, 1)\n"
     ]
    }
   ],
   "source": [
    "# cell 8\n",
    "y = y.reshape(-1, 1)  # -1 will tell numpy to infer the number of rows automatically and we have specified column as 1\n",
    "print(f\"Dimension of label vector: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the entire dataset into train, validation and test sets**\n",
    "\n",
    "* We will randomly split our dataset both X and y into train, validation and test sets in the proportion of 60:20:20 respectively.\n",
    "\n",
    "* For this we will use train_test_split() function from sklearn library.\n",
    "\n",
    "* We will achieve this task in two steps:\n",
    "\n",
    "    a. First split the entire dataset into train and validation set in the ratio 60:40.  \n",
    "    \n",
    "    b. Then, split the validation set into validation set and test set in the ratio 50:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 9\n",
    "# a. Splitting the data into train, and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# b. Splitting the validation set into validation and test set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of training feature matrix: (327, 13)\n",
      "Dimension of training label vector: (327, 1)\n",
      "==================================================\n",
      "Dimension of validation feature matrix: (109, 13)\n",
      "Dimension of validation label vector: (109, 1)\n",
      "==================================================\n",
      "Dimension of testing feature matrix: (109, 13)\n",
      "Dimension of testing label vector: (109, 1)\n"
     ]
    }
   ],
   "source": [
    "# cell 10\n",
    "print(f\"Dimension of training feature matrix: {X_train.shape}\")\n",
    "print(f\"Dimension of training label vector: {y_train.shape}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dimension of validation feature matrix: {X_val.shape}\")\n",
    "print(f\"Dimension of validation label vector: {y_val.shape}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dimension of testing feature matrix: {X_test.shape}\")\n",
    "print(f\"Dimension of testing label vector: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scaling**\n",
    "* Can be done in two ways:\n",
    "\n",
    "    1. Feature Normalization:\n",
    "        * Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. \n",
    "        \n",
    "        * It is also known as Min-Max scaling.\n",
    "\n",
    "        $$\n",
    "            X_{\\text{norm}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "        \n",
    "        $$\n",
    "    2. Feature Standardization\n",
    "        * Standardization is scaling technique where the values are centered around the mean with a unit standard deviation. \n",
    "        \n",
    "        * This means that the mean of the feature becomes zero, and the resultant distribution has a unit standard deviation.\n",
    "\n",
    "        $$\n",
    "            X_{\\text{std}} = \\frac{X - \\mu}{\\sigma}\n",
    "        $$\n",
    "\n",
    "* For feature scaling we will use **TRAINING SET** to compute X_min, X_max (for normalization) and X_mean and X_std (for standardization).\n",
    "\n",
    "* Then the same X_min, X_max, X_mean or X_std values from training sets are used for scaling features from validation and test sets.\n",
    "\n",
    "* We will use feature standardization in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "# Function to standardize training features\n",
    "def training_feature_standardization(X_train):\n",
    "    # Calculate mean and standard deviation from the training set\n",
    "    X_train_mean = X_train.mean(axis=0)  # axis=0 means columnwise operation\n",
    "    X_train_std = X_train.astype(np.float32).std(axis=0)\n",
    "    \n",
    "    # Reshaping the mean and standard deviation\n",
    "    X_train_mean = X_train_mean.reshape(1, -1)\n",
    "    X_train_std = X_train_std.reshape(1, -1)\n",
    "    \n",
    "    # Standardize training set\n",
    "    X_train_scaled = (X_train - X_train_mean) / X_train_std\n",
    "    \n",
    "    return X_train_mean, X_train_std, X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "# Function to standardize the test features\n",
    "# This same function can be used to standardize the validation sets\n",
    "def test_feature_standardization(X_train_mean, X_train_std, X_test):\n",
    "    \n",
    "    X_test_scaled = (X_test - X_train_mean) / X_train_std\n",
    "    \n",
    "    return X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 13\n",
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, X_train_mean, X_train_std, learning_rate=0.001, n_iters=1000):\n",
    "        self.X_train_mean = X_train_mean\n",
    "        self.X_train_std = X_train_std\n",
    "        self.theta = None\n",
    "        self.n_iters = n_iters\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Containers for losses and theta\n",
    "        self.loss_history = []\n",
    "        self.theta_history = []\n",
    "        \n",
    "        \n",
    "    def compute_MSE_loss(self, y: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Function to compute Mean Squared Error\n",
    "\n",
    "        Args:\n",
    "            y (np.ndarray): Label vector of shape (m, 1)\n",
    "            y_pred (np.ndarray): Predicted label vector of shape (m, 1)\n",
    "\n",
    "        Returns:\n",
    "            float: Loss value\n",
    "        \"\"\"\n",
    "        m = len(y) # m = y.shape[0] i.e. number of samples\n",
    "        loss = np.sum((y_pred - y) ** 2) / (2 * m)\n",
    "        return loss\n",
    "    \n",
    "    def gradient_descent(self, X: np.ndarray, y: np.ndarray, y_pred: np.ndarray, theta: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Function to calculate gradients and update parameters\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Input feature matrix of shape (m, n+1)\n",
    "            y (np.ndarray): Label vector of shape (m, 1)\n",
    "            y_pred (np.ndarray): Predicted label vector of shape (m, 1)\n",
    "            theta (np.ndarray): linear regression model parameter vector of shape (n+1, 1)\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Updated parameter vector: theta of shape (n+1, 1)\n",
    "        \"\"\"\n",
    "        m = len(y)\n",
    "        \n",
    "        # Compute gradients\n",
    "        # Shape of gradients is (n+1, 1)\n",
    "        gradients = np.dot(X.T, (y_pred - y)) / m\n",
    "        \n",
    "        # Update parameters\n",
    "        theta = theta - self.learning_rate * gradients\n",
    "        \n",
    "        return theta\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Tuple[List, List]:\n",
    "        \"\"\"\n",
    "        Function to fit linear regression model\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Scaled input feature matrix of shape (m, n+1)\n",
    "            y (np.ndarray): Label vector of shape (m, 1)\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List, List]: Returns loss history and theta history\n",
    "        \"\"\"\n",
    "        # Add new dimension to X\n",
    "        new_dimension = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((new_dimension, X))\n",
    "        \n",
    "        # Initialize theta\n",
    "        self.theta = np.zeros((X.shape[1], 1))\n",
    "        \n",
    "        # Training loop\n",
    "        for i in range(self.n_iters):\n",
    "            self.theta_history.append(self.theta)\n",
    "            y_pred = np.dot(X, self.theta)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = self.compute_MSE_loss(y, y_pred)\n",
    "            self.loss_history.append(loss)\n",
    "            \n",
    "            # Perform gradient descent\n",
    "            self.theta = self.gradient_descent(X, y, y_pred, self.theta)\n",
    "            \n",
    "            # Print loss every 100 iterations\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration {i}: MSE Loss = {loss}\")\n",
    "                print(\"=\" * 50)\n",
    "                \n",
    "        return self.loss_history, self.theta_history\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray, y: np.ndarray) -> Tuple[float, float]:\n",
    "        \"\"\"Function to evaluate trained model on test and validation set\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Scaled input feature matrix from test or validation set of shape (test/validation_samples, n+1)\n",
    "            y (np.ndarray): Label vector from test or validation set of shape (test/validation_samples, 1)\n",
    "\n",
    "        Returns:\n",
    "            Tuple[float, float]: Returns MSE loss and Coefficient of Determination (R^2)\n",
    "        \"\"\"\n",
    "        # Add new dimension to X\n",
    "        new_dimension = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((new_dimension, X))\n",
    "        y_pred = np.dot(X, self.theta)     \n",
    "        mse_loss = self.compute_MSE_loss(y, y_pred)\n",
    "        r2 = 1 - (np.sum((y - y_pred) ** 2) / np.sum((y - y.mean()) ** 2))  # coefficient of determination\n",
    "        return mse_loss, r2\n",
    "           \n",
    "    def predict(self, X):\n",
    "        \"\"\"Function to predict using trained model on data that are not in the dataset\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Scaled input feature matrix of shape (m, n+1)\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Returns the predicted price of shape (m, 1)\n",
    "        \"\"\"\n",
    "        # Add new dimension to X\n",
    "        new_dimension = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((new_dimension, X))\n",
    "        y_pred = np.dot(X, self.theta)\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: MSE Loss = 11898223945387.768\n",
      "==================================================\n",
      "Iteration 100: MSE Loss = 1889850670758.359\n",
      "==================================================\n",
      "Iteration 200: MSE Loss = 646809723532.819\n",
      "==================================================\n",
      "Iteration 300: MSE Loss = 479356963320.85864\n",
      "==================================================\n",
      "Iteration 400: MSE Loss = 456261378050.4726\n",
      "==================================================\n",
      "Iteration 500: MSE Loss = 452895898484.9235\n",
      "==================================================\n",
      "Iteration 600: MSE Loss = 452329929716.92\n",
      "==================================================\n",
      "Iteration 700: MSE Loss = 452203573461.2716\n",
      "==================================================\n",
      "Iteration 800: MSE Loss = 452163907806.7867\n",
      "==================================================\n",
      "Iteration 900: MSE Loss = 452148193954.3902\n",
      "==================================================\n",
      "Training MSE Loss after completion of training: 452141326600.376\n"
     ]
    }
   ],
   "source": [
    "# cell 14\n",
    "# Prepare training, validation and test sets by standardizing features\n",
    "X_train_mean, X_train_std, X_train_scaled = training_feature_standardization(X_train)\n",
    "\n",
    "X_val_scaled = test_feature_standardization(X_train_mean, X_train_std, X_val)\n",
    "\n",
    "X_test_scaled = test_feature_standardization(X_train_mean, X_train_std, X_test)\n",
    "\n",
    "# Instantiate LinearRegression Model\n",
    "lr_model = LinearRegression(X_train_mean=X_train_mean, X_train_std=X_train_std, learning_rate=0.01, n_iters=1000)\n",
    "\n",
    "# Fit the model with training data\n",
    "loss_history, theta_history = lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training MSE Loss after completion of training: {loss_history[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the Learning Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell 15\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.lineplot(loss_history)\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.xlabel(\"#Iterations\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation on Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 749652843046.9702\n",
      "Validation R^2: 0.6737946158989427\n"
     ]
    }
   ],
   "source": [
    "# cell 16\n",
    "# Evaluate the model on validation set\n",
    "val_loss, val_r2 = lr_model.evaluate(X_val_scaled, y_val)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation R^2: {val_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the Validation Loss is higher than Training Loss. R^2 is greater than 0.5 i.e. 0.67 which is just fine but could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection or Hyperparameter Tuning**\n",
    "* We will tune learning rate in this tutorial using grid search i.e. we will set predefined set of values for learning rate.\n",
    "\n",
    "* For every learning rate, we will evaluate the model using validation set.\n",
    "\n",
    "* We will set the number of iterations to 200(can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING EXPERIMENT 1 WITH LEARNING RATE: 0.1\n",
      "Iteration 0: MSE Loss = 11898223945387.768\n",
      "==================================================\n",
      "Iteration 100: MSE Loss = 452140524849.5005\n",
      "==================================================\n",
      "RUNNING EXPERIMENT 2 WITH LEARNING RATE: 0.01\n",
      "Iteration 0: MSE Loss = 11898223945387.768\n",
      "==================================================\n",
      "Iteration 100: MSE Loss = 1889850670758.359\n",
      "==================================================\n",
      "RUNNING EXPERIMENT 3 WITH LEARNING RATE: 0.001\n",
      "Iteration 0: MSE Loss = 11898223945387.768\n",
      "==================================================\n",
      "Iteration 100: MSE Loss = 9660370619205.281\n",
      "==================================================\n",
      "RUNNING EXPERIMENT 4 WITH LEARNING RATE: 0.0001\n",
      "Iteration 0: MSE Loss = 11898223945387.768\n",
      "==================================================\n",
      "Iteration 100: MSE Loss = 11649559715022.69\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# cell 17\n",
    "# Prepare training, validation and test sets by standardizing features\n",
    "X_train_mean, X_train_std, X_train_scaled = training_feature_standardization(X_train)\n",
    "\n",
    "X_val_scaled = test_feature_standardization(X_train_mean, X_train_std, X_val)\n",
    "\n",
    "X_test_scaled = test_feature_standardization(X_train_mean, X_train_std, X_test)\n",
    "\n",
    "learning_rate_set = [0.1, 0.01, 0.001, 0.0001]\n",
    "val_loss_set = []\n",
    "val_r2_score_set = []\n",
    "model_list = []\n",
    "\n",
    "for exp_num, lr in enumerate(learning_rate_set):\n",
    "    print(f\"RUNNING EXPERIMENT {exp_num+1} WITH LEARNING RATE: {lr}\")\n",
    "    my_lr_model = LinearRegression(X_train_mean=X_train_mean, X_train_std=X_train_std, learning_rate=lr, n_iters=200)\n",
    "    _, _ = my_lr_model.fit(X_train_scaled, y_train)\n",
    "    loss, r2 = my_lr_model.evaluate(X_val_scaled, y_val)\n",
    "    val_loss_set.append(loss)\n",
    "    val_r2_score_set.append(r2)\n",
    "    model_list.append(my_lr_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study Experiment Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss for different experiments with lr=[0.1, 0.01, 0.001, 0.0001]: [749922359341.2747, 1045256820019.552, 10234978132378.688, 14977840435704.896]\n",
      "Validation R^2 for different experiments with lr=[0.1, 0.01, 0.001, 0.0001]: [0.6736773380587792, 0.5451649311795328, -3.453668126393434, -5.517486377394201]\n"
     ]
    }
   ],
   "source": [
    "# cell 18\n",
    "print(f\"Validation loss for different experiments with lr={learning_rate_set}: {val_loss_set}\")\n",
    "print(f\"Validation R^2 for different experiments with lr={learning_rate_set}: {val_r2_score_set}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative value for R^2 indicates that the models does not fit our data i.e. the model fails to understand the data pattern. If you find harder to compare loss due to its high value we could normalize that as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss for different experiments with lr=[0.1, 0.01, 0.001, 0.0001]: [0.05006879 0.06978688 0.68334138 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# cell 19\n",
    "print(f\"Validation loss for different experiments with lr={learning_rate_set}: {np.array(val_loss_set)/max(val_loss_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among those four models that we get from four different experiments, the model that is trained with lr=0.1 for 200 epochs yields higher R^2. So, we will select that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Best Model with Test Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 756303346851.1155\n",
      "Test R^2 score: 0.6742297858400923\n"
     ]
    }
   ],
   "source": [
    "# cell 20\n",
    "best_model = model_list[np.argmax(val_r2_score_set)]  # np.argmax will return the index of max value\n",
    "\n",
    "loss, r2 = best_model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Test MSE Loss: {loss}\")\n",
    "print(f\"Test R^2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferencing model with our own data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area', 'bedrooms', 'bathrooms', 'stories', 'parking', 'mainroad_yes',\n",
      "       'guestroom_yes', 'basement_yes', 'hotwaterheating_yes',\n",
      "       'airconditioning_yes', 'prefarea_yes',\n",
      "       'furnishingstatus_semi-furnished', 'furnishingstatus_unfurnished'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# cell 21\n",
    "features = df.drop(\"price\", axis=1).columns\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to give all these features as input to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 22\n",
    "data = np.array((\n",
    "    100, # area\n",
    "    2, # no. of bedrooms\n",
    "    1,  # no. of bathrooms\n",
    "    1,  # no. of stories\n",
    "    1,  # parking\n",
    "    1,  # mainroad_yes\n",
    "    1,  # guestroom_yes\n",
    "    0,  # basement_yes\n",
    "    1,  # hotwaterheating_yes\n",
    "    0,  # airconditioning_yes\n",
    "    0,  # prefarea_yes\n",
    "    1,  # furnishingstatus_semifurnished\n",
    "    0   # furnishingstatus_unfurnished\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price: [[3529794.9892266775]]\n"
     ]
    }
   ],
   "source": [
    "# cell 23\n",
    "data = data.reshape(1, -1)\n",
    "data_scaled = test_feature_standardization(X_train_mean, X_train_std, data)\n",
    "\n",
    "prediction = best_model.predict(data_scaled)\n",
    "print(f\"Predicted price: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Optional Assignments**\n",
    "\n",
    "* As we have noticed, our best model has R^2 score of around 0.67 which is not a very good score. Try to improve our model score.\n",
    "\n",
    "* You could try EDA and do some feature engineering.\n",
    "\n",
    "* You could add some higher order features or feature interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soccer-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
